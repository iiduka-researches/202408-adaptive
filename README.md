# A general framework of Riemannian adaptive optimization methods with a convergence analysis
Code for reproducing experiments in our paper.

## Abstract
This paper proposes a general framework of Riemannian adaptive optimization methods.
The framework encapsulates several stochastic optimization algorithms on Riemannian man-
ifolds and incorporates the mini-batch strategy that is often used in deep learning. Within
this framework, we also propose AMSGrad on embedded submanifolds of Euclidean space.
Moreover, we give convergence analyses valid for both a constant and a diminishing step
size. Our analyses also reveal the relationship between the convergence rate and mini-
batch size. In numerical experiments, we applied the proposed algorithm to principal
component analysis and the low-rank matrix completion problem, which can be consid-
ered to be Riemannian optimization problems.
